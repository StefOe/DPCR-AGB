# @package training
# Those arguments defines the training hyper-parameters
epochs: 310
num_workers: 4
batch_size: 32
cuda: 0
shuffle: True
optim:
  base_lr: 0.005
  grad_clip: 100
  optimizer:
#    class: SGD
#    params:
#      momentum: 0.98
#      lr: ${training.optim.base_lr} # The path is cut from training
#      weight_decay: 1e-3
    class: AdaBelief
    params:
      lr: ${training.optim.base_lr} # The path is cut from training
      weight_decay: 1e-2
  lr_scheduler: ${lr_scheduler}
#  bn_scheduler:
#    bn_policy: "step_decay"
#    params:
#      bn_momentum: 0.98
#      bn_decay: 0.9
#      decay_step: 1000
#      bn_clip: 1e-2
weight_name: "latest" # Used during resume, select with model to load from [miou, macc, acc..., latest]
enable_cudnn: True
checkpoint_dir: ""

# Those arguments within experiment defines which model, dataset, and task to be created for benchmarking
# parameters for Weights and Biases
wandb:
  project: nfi
  log: True
  name: ${model_name}
  public: True # It will be display the model within wandb log, else not.
  config:
    model_name: ${model_name}
    features: ${data.features}
    batch_size: ${training.batch_size}
    base_lr: ${training.optim.base_lr}
    transform_type: ${data.transform_type}


# parameters for TensorBoard Visualization
tensorboard:
  log: False
  pytorch_profiler:
    log: False # activate PyTorch Profiler in TensorBoard
    nb_epoch: 3 # number of epochs to profile (0 -> all).
    skip_first: 10 # number of first iterations to skip.
    wait: 5 # number of iterations where the profiler is disable.
    warmup: 3 # number of iterations where the profiler starts tracing but the results are discarded. This is for reducing the profiling overhead. The overhead at the beginning of profiling is high and easy to bring skew to the profiling result.
    active: 5 # number of iterations where the profiler is active and records events.
    repeat: 0 # number of cycle wait/warmup/active to realise before stoping profiling (0 -> all).
    record_shapes: True # save information about operatorâ€™s input shapes.
    profile_memory: True # track tensor memory allocation/deallocation.
    with_stack: True # record source information (file and line number) for the ops.
    with_flops: True # use formula to estimate the FLOPS of specific operators (matrix multiplication and 2D convolution).


enable_mixed: True
